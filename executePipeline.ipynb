{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:38:25.814759",
     "start_time": "2016-10-27T12:38:25.807739"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_union\n",
    "from numpy import ravel\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:38:25.854865",
     "start_time": "2016-10-27T12:38:25.815761"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# contains all methods and classes for FeatureUnion\n",
    "## generic read_csv\n",
    "\n",
    "#example\n",
    "class Regular(TransformerMixin):\n",
    "    #return itself\n",
    "    def __init__(self, df):\n",
    "        # TODO build in args so that we can pass things to read_csv\n",
    "        self.df = df\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.df\n",
    "\n",
    "#example\n",
    "class LoadCSV(TransformerMixin):\n",
    "    def __init__(self, filename, **kwargs):\n",
    "        # TODO build in args so that we can pass things to read_csv\n",
    "        self.filename = filename\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # we assume the first CSV entry is always the ID\n",
    "        temp = pd.read_csv(self.filename, index_col = 0, **self.kwargs)\n",
    "        return temp\n",
    "\n",
    "def load_data(directory, files, cols):\n",
    "    df = None\n",
    "    for i, f in enumerate(files):\n",
    "        print(f)\n",
    "        subset = None\n",
    "        \n",
    "        for i, chunk in enumerate(pd.read_csv(directory + f,\n",
    "                                              usecols=cols[i],\n",
    "                                              chunksize=50000,\n",
    "                                              low_memory=False)):\n",
    "            if i % 5 == 0:\n",
    "                print('Processing chunk %d' % i)\n",
    "            if subset is None:\n",
    "                subset = chunk.copy()\n",
    "            else:\n",
    "                subset = pd.concat([subset, chunk])\n",
    "            del chunk\n",
    "            gc.collect()\n",
    "            \n",
    "        if df is None:\n",
    "            df = subset.copy()\n",
    "        else:\n",
    "            df = pd.merge(df, subset.copy(), on=\"Id\")\n",
    "        del subset\n",
    "        gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:38:41.729091",
     "start_time": "2016-10-27T12:38:25.855868"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load in targets\n",
    "base = pd.read_csv(\"data/train_numeric.csv\", usecols = ['Id','Response'])\n",
    "target = base.loc[:,['Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:38:41.738117",
     "start_time": "2016-10-27T12:38:41.730110"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_files = ['train_date.csv',\n",
    "              'train_numeric.csv']\n",
    "\n",
    "test_files = ['test_date.csv',\n",
    "             'test_numeric.csv']\n",
    "\n",
    "train_cols = [\n",
    "        ['Id',\n",
    "         'L3_S30_D3496', 'L3_S30_D3506',\n",
    "         'L3_S30_D3501', 'L3_S30_D3516',\n",
    "         'L3_S30_D3511'],\n",
    "        ['Id',\n",
    "         'L1_S24_F1846', 'L3_S32_F3850',\n",
    "         'L1_S24_F1695', 'L1_S24_F1632',\n",
    "         'L3_S33_F3855', 'L1_S24_F1604',\n",
    "         'L3_S29_F3407', 'L3_S33_F3865',\n",
    "         'L3_S38_F3952', 'L1_S24_F1723',\n",
    "         'Response'],\n",
    "        ['Id','Fail']]\n",
    "\n",
    "test_cols = [\n",
    "        ['Id',\n",
    "         'L3_S30_D3496', 'L3_S30_D3506',\n",
    "         'L3_S30_D3501', 'L3_S30_D3516',\n",
    "         'L3_S30_D3511'],\n",
    "        ['Id',\n",
    "         'L1_S24_F1846', 'L3_S32_F3850',\n",
    "         'L1_S24_F1695', 'L1_S24_F1632',\n",
    "         'L3_S33_F3855', 'L1_S24_F1604',\n",
    "         'L3_S29_F3407', 'L3_S33_F3865',\n",
    "         'L3_S38_F3952', 'L1_S24_F1723'],\n",
    "        ['Id','Fail']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:39:57.560806",
     "start_time": "2016-10-27T12:38:41.739118"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_date.csv\n",
      "Processing chunk 0\n",
      "Processing chunk 5\n",
      "Processing chunk 10\n",
      "Processing chunk 15\n",
      "Processing chunk 20\n",
      "train_numeric.csv\n",
      "Processing chunk 0\n",
      "Processing chunk 5\n",
      "Processing chunk 10\n",
      "Processing chunk 15\n",
      "Processing chunk 20\n",
      "(1183747, 17)\n"
     ]
    }
   ],
   "source": [
    "train_rawfeatures = load_data('data/', train_files, train_cols)\n",
    "print(train_rawfeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:41:13.426091",
     "start_time": "2016-10-27T12:39:57.561811"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_date.csv\n",
      "Processing chunk 0\n",
      "Processing chunk 5\n",
      "Processing chunk 10\n",
      "Processing chunk 15\n",
      "Processing chunk 20\n",
      "test_numeric.csv\n",
      "Processing chunk 0\n",
      "Processing chunk 5\n",
      "Processing chunk 10\n",
      "Processing chunk 15\n",
      "Processing chunk 20\n",
      "(1183748, 16)\n"
     ]
    }
   ],
   "source": [
    "test_rawfeatures = load_data('data/', test_files, test_cols)\n",
    "print(test_rawfeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:41:13.434110",
     "start_time": "2016-10-27T12:41:13.428094"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'L3_S30_D3496', 'L3_S30_D3501', 'L3_S30_D3506', 'L3_S30_D3511',\n",
       "       'L3_S30_D3516', 'L1_S24_F1604', 'L1_S24_F1632', 'L1_S24_F1695',\n",
       "       'L1_S24_F1723', 'L1_S24_F1846', 'L3_S29_F3407', 'L3_S32_F3850',\n",
       "       'L3_S33_F3855', 'L3_S33_F3865', 'L3_S38_F3952'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_rawfeatures = train_mindate\n",
    "#test_rawfeatures = test_mindate\n",
    "test_rawfeatures.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:41:13.936449",
     "start_time": "2016-10-27T12:41:13.437119"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove Id and Response\n",
    "train_rawfeatures = train_rawfeatures[train_rawfeatures.columns.difference(['Id', 'Response'])]\n",
    "test_rawfeatures = test_rawfeatures[test_rawfeatures.columns.difference(['Id', 'Response'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:41:15.770744",
     "start_time": "2016-10-27T12:41:13.937449"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make featureunions\n",
    "\n",
    "#unionargs = ['data/{}_fail_date_score.csv'.format('train')]#\n",
    "#\n",
    "#def deliverunion(train = True):\n",
    "#    # fileanme, than args\n",
    "#    arglist = []\n",
    "#    arglist.append(['data/train_fail_date_score.csv'])\n",
    "#    if train:#\n",
    "#\n",
    "features = make_union(LoadCSV('data/train_fail_date_score.csv'), \n",
    "                      LoadCSV('data/train_min_date.csv'),\n",
    "                      LoadCSV('data/train_s32_s33_s34.csv'),\n",
    "                      Regular(train_rawfeatures))\n",
    "# mindate's best columns, Huey's (is S32, S33, S34), \n",
    "# nathan's cyclic thing, fail_date_score, useful date columns\n",
    "X = features.fit_transform(1)\n",
    "y = base['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:41:17.621183",
     "start_time": "2016-10-27T12:41:15.771746"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = make_union(LoadCSV('data/test_fail_date_score.csv'), \n",
    "                  LoadCSV('data/test_min_date.csv'),\n",
    "                  LoadCSV('data/test_s32_s33_s34.csv'),\n",
    "                  Regular(test_rawfeatures))\n",
    "X_test = test.fit_transform(1)\n",
    "df_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:41:17.628165",
     "start_time": "2016-10-27T12:41:17.622148"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if X.shape[1] != X_test.shape[1]:\n",
    "    print('loaded in CSVs wrong')\n",
    "\n",
    "#clf = XGBClassifier(base_score=0.005, seed=24)\n",
    "#clf.fit(X,y)\n",
    "##original_preds = np.ones(y.shape[0])\n",
    "#original_raw_preds = clf.predict_proba(X)\n",
    "#original_preds = (clf.predict_proba(X)[:,1] > 0.05).astype(np.int8)\n",
    "#newpreds = (clf.predict_proba(test)[:,1] > 0.05).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:46:24.917016",
     "start_time": "2016-10-27T12:41:17.631173"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, ROC AUC: 0.910\n",
      "fold 1, ROC AUC: 0.902\n",
      "fold 2, ROC AUC: 0.894\n",
      "0.90157738493\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(max_depth=5, base_score=0.005, seed=37)\n",
    "cv = StratifiedKFold(y, n_folds=3, random_state=37)\n",
    "preds = np.ones(y.shape[0])\n",
    "dfX = pd.DataFrame(X)\n",
    "\n",
    "for i, (infold, outfold) in enumerate(cv):\n",
    "    preds[outfold] = clf.fit(dfX.loc[infold], y[infold]).predict_proba(dfX.loc[outfold])[:,1]\n",
    "    print(\"fold {}, ROC AUC: {:.3f}\".format(i, roc_auc_score(y[outfold], preds[outfold])))\n",
    "print(roc_auc_score(y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:46:37.327998",
     "start_time": "2016-10-27T12:46:24.917988"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.387231789121\n"
     ]
    }
   ],
   "source": [
    "# Pick the best threshold out-of-fold\n",
    "thresholds = np.linspace(0.01, 0.99, 50)\n",
    "mcc = np.array([matthews_corrcoef(y, preds>thr) for thr in thresholds])\n",
    "plt.plot(thresholds, mcc)\n",
    "best_threshold = thresholds[mcc.argmax()]\n",
    "print(mcc.max())\n",
    "preds = (clf.predict_proba(df_test)[:,1] > best_threshold).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-27T12:46:43.266796",
     "start_time": "2016-10-27T12:46:37.329001"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Submit\n",
    "sub = pd.read_csv(\"data/sample_submission.csv\", index_col=0)\n",
    "sub[\"Response\"] = preds\n",
    "sub.to_csv(\"pipesubmission.csv.gz\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
