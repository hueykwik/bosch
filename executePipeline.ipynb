{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:40:29.929623",
     "start_time": "2016-11-01T16:40:25.095770"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_union\n",
    "from numpy import ravel\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:40:30.036907",
     "start_time": "2016-11-01T16:40:29.930625"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Usage: Use the TransformerMixin classes below to create features and then use FeatureUnions\n",
    "# to concatenate them together.\n",
    "\n",
    "# Example transformer to take a data frame and then return some features via the transform()\n",
    "# method.\n",
    "class Regular(TransformerMixin):\n",
    "    #return itself, use this for when you have a dataframe already in the script base\n",
    "    def __init__(self, df):\n",
    "        # TODO build in args so that we can pass things to read_csv\n",
    "        self.df = df\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.df\n",
    "\n",
    "# Loads a CSV and then returns a set of features.\n",
    "class LoadCSV(TransformerMixin):\n",
    "    # use this to load in an external csv, it accepts kwargs to feed to pd.read_csv()\n",
    "    def __init__(self, filename, **kwargs):\n",
    "        # TODO build in args so that we can pass things to read_csv\n",
    "        self.filename = filename\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # we assume the first CSV entry is always the ID\n",
    "        temp = pd.read_csv(self.filename, index_col = 0, **self.kwargs)\n",
    "        return temp\n",
    "\n",
    "# Loads from a directory in chunks and then returns a dataframe.\n",
    "def load_data(directory, files, cols):\n",
    "    # Huey's older loading method, should deprecate this I think\n",
    "    df = None\n",
    "    for i, f in enumerate(files):\n",
    "        print(f)\n",
    "        subset = None\n",
    "        \n",
    "        for i, chunk in enumerate(pd.read_csv(directory + f,\n",
    "                                              usecols=cols[i],\n",
    "                                              chunksize=50000,\n",
    "                                              low_memory=False)):\n",
    "            if i % 5 == 0:\n",
    "                print('Processing chunk %d' % i)\n",
    "            if subset is None:\n",
    "                subset = chunk.copy()\n",
    "            else:\n",
    "                subset = pd.concat([subset, chunk])\n",
    "            del chunk\n",
    "            gc.collect()\n",
    "            \n",
    "        if df is None:\n",
    "            df = subset.copy()\n",
    "        else:\n",
    "            df = pd.merge(df, subset.copy(), on=\"Id\")\n",
    "        del subset\n",
    "        gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:40:52.229922",
     "start_time": "2016-11-01T16:40:30.037911"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load in targets\n",
    "base = pd.read_csv(\"data/train_numeric.csv\", usecols = ['Id','Response'])\n",
    "target = base.loc[:,['Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:40:52.238946",
     "start_time": "2016-11-01T16:40:52.230924"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_files = ['train_date.csv',\n",
    "              'train_numeric.csv']\n",
    "\n",
    "test_files = ['test_date.csv',\n",
    "             'test_numeric.csv']\n",
    "\n",
    "train_cols = [\n",
    "        ['Id',\n",
    "         'L3_S30_D3496', 'L3_S30_D3506',\n",
    "         'L3_S30_D3501', 'L3_S30_D3516',\n",
    "         'L3_S30_D3511'],\n",
    "        ['Id',\n",
    "         'L1_S24_F1846', 'L3_S32_F3850',\n",
    "         'L1_S24_F1695', 'L1_S24_F1632',\n",
    "         'L3_S33_F3855', 'L1_S24_F1604',\n",
    "         'L3_S29_F3407', 'L3_S33_F3865',\n",
    "         'L3_S38_F3952', 'L1_S24_F1723',\n",
    "         'Response'],\n",
    "        ['Id','Fail']]\n",
    "\n",
    "test_cols = [\n",
    "        ['Id',\n",
    "         'L3_S30_D3496', 'L3_S30_D3506',\n",
    "         'L3_S30_D3501', 'L3_S30_D3516',\n",
    "         'L3_S30_D3511'],\n",
    "        ['Id',\n",
    "         'L1_S24_F1846', 'L3_S32_F3850',\n",
    "         'L1_S24_F1695', 'L1_S24_F1632',\n",
    "         'L3_S33_F3855', 'L1_S24_F1604',\n",
    "         'L3_S29_F3407', 'L3_S33_F3865',\n",
    "         'L3_S38_F3952', 'L1_S24_F1723'],\n",
    "        ['Id','Fail']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:42:23.825530",
     "start_time": "2016-11-01T16:40:52.239948"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_date.csv\n",
      "Processing chunk 0\n",
      "Processing chunk 5\n",
      "Processing chunk 10\n",
      "Processing chunk 15\n",
      "Processing chunk 20\n",
      "train_numeric.csv\n",
      "Processing chunk 0\n",
      "Processing chunk 5\n",
      "Processing chunk 10\n",
      "Processing chunk 15\n",
      "Processing chunk 20\n",
      "(1183747, 17)\n"
     ]
    }
   ],
   "source": [
    "train_raw_features = load_data('data/', train_files, train_cols)\n",
    "print(train_raw_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:44:01.212395",
     "start_time": "2016-11-01T16:42:23.826533"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_date.csv\n",
      "Processing chunk 0\n",
      "Processing chunk 5\n",
      "Processing chunk 10\n",
      "Processing chunk 15\n",
      "Processing chunk 20\n",
      "test_numeric.csv\n",
      "Processing chunk 0\n",
      "Processing chunk 5\n",
      "Processing chunk 10\n",
      "Processing chunk 15\n",
      "Processing chunk 20\n",
      "(1183748, 16)\n"
     ]
    }
   ],
   "source": [
    "test_raw_features = load_data('data/', test_files, test_cols)\n",
    "print(test_raw_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T17:16:01.349099",
     "start_time": "2016-11-01T17:16:00.843752"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Response'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5102c524c169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_raw_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Dave\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Response'"
     ]
    }
   ],
   "source": [
    "train_raw_features.Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:44:01.234457",
     "start_time": "2016-11-01T16:44:01.216412"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'L3_S30_D3496', 'L3_S30_D3501', 'L3_S30_D3506', 'L3_S30_D3511',\n",
       "       'L3_S30_D3516', 'L1_S24_F1604', 'L1_S24_F1632', 'L1_S24_F1695',\n",
       "       'L1_S24_F1723', 'L1_S24_F1846', 'L3_S29_F3407', 'L3_S32_F3850',\n",
       "       'L3_S33_F3855', 'L3_S33_F3865', 'L3_S38_F3952'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_rawfeatures = train_mindate\n",
    "#test_rawfeatures = test_mindate\n",
    "test_raw_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:44:02.048619",
     "start_time": "2016-11-01T16:44:01.240476"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove Id and Response\n",
    "train_raw_features = train_raw_features[train_raw_features.columns.difference(['Id', 'Response'])]\n",
    "test_raw_features = test_raw_features[test_raw_features.columns.difference(['Id', 'Response'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:44:05.674261",
     "start_time": "2016-11-01T16:44:02.049621"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make FeatureUnions\n",
    "# load in each piece of data from 'data/' that you want\n",
    "features = make_union(LoadCSV('data/train_fail_date_score.csv'), \n",
    "                          # Counts the number of failures that \n",
    "                          # happened between the first and last datetime.\n",
    "                      LoadCSV('data/train_min_date.csv'),\n",
    "                          # This is the so-called \"magic\" feature.\n",
    "                      LoadCSV('data/train_s32_s33_s34.csv'),\n",
    "                          # Indicates whether part passed through S32, S33, or S34.\n",
    "                      Regular(train_raw_features),\n",
    "                      LoadCSV('data/train_pca2comp.csv'))\n",
    "\n",
    "#                      LoadCSV('data/train_id_rates_max.csv'),\n",
    "#                      LoadCSV('data/train_id_rates_total.csv'))\n",
    "# mindate's best columns, Huey's (is S32, S33, S34), \n",
    "# nathan's cyclic thing, fail_date_score, useful date columns\n",
    "\n",
    "\n",
    "X = features.fit_transform(1)\n",
    "y = base['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:44:08.633128",
     "start_time": "2016-11-01T16:44:05.675261"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = make_union(LoadCSV('data/test_fail_date_score.csv'), \n",
    "                  LoadCSV('data/test_min_date.csv'),\n",
    "                  LoadCSV('data/test_s32_s33_s34.csv'),\n",
    "                  Regular(test_raw_features),\n",
    "                  LoadCSV('data/test_pca2comp.csv'))\n",
    "#                  LoadCSV('data/test_id_rates_max.csv'),\n",
    "#                  LoadCSV('data/test_id_rates_total.csv'))\n",
    "X_test = test.fit_transform(1)\n",
    "df_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:44:08.639144",
     "start_time": "2016-11-01T16:44:08.634129"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if X.shape[1] != X_test.shape[1]:\n",
    "    print('loaded in CSVs wrong')\n",
    "\n",
    "#clf = XGBClassifier(base_score=0.005, seed=24)\n",
    "#clf.fit(X,y)\n",
    "##original_preds = np.ones(y.shape[0])\n",
    "#original_raw_preds = clf.predict_proba(X)\n",
    "#original_preds = (clf.predict_proba(X)[:,1] > 0.05).astype(np.int8)\n",
    "#newpreds = (clf.predict_proba(test)[:,1] > 0.05).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:50:58.496929",
     "start_time": "2016-11-01T16:44:08.641150"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, ROC AUC: 0.911\n",
      "fold 1, ROC AUC: 0.903\n",
      "fold 2, ROC AUC: 0.894\n",
      "0.902520881739\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(max_depth=5, base_score=0.005, seed=37)\n",
    "cv = StratifiedKFold(y, n_folds=3, random_state=37)\n",
    "preds = np.ones(y.shape[0])\n",
    "dfX = pd.DataFrame(X)\n",
    "\n",
    "for i, (infold, outfold) in enumerate(cv):\n",
    "    preds[outfold] = clf.fit(dfX.loc[infold], y[infold]).predict_proba(dfX.loc[outfold])[:,1]\n",
    "    print(\"fold {}, ROC AUC: {:.3f}\".format(i, roc_auc_score(y[outfold], preds[outfold])))\n",
    "print(roc_auc_score(y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:51:13.424086",
     "start_time": "2016-11-01T16:50:58.498936"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.386369081784\n"
     ]
    }
   ],
   "source": [
    "# Pick the best threshold out-of-fold\n",
    "thresholds = np.linspace(0.01, 0.99, 50)\n",
    "mcc = np.array([matthews_corrcoef(y, preds>thr) for thr in thresholds])\n",
    "plt.plot(thresholds, mcc)\n",
    "best_threshold = thresholds[mcc.argmax()]\n",
    "print(mcc.max())\n",
    "preds = (clf.predict_proba(df_test)[:,1] > best_threshold).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T16:51:20.238236",
     "start_time": "2016-11-01T16:51:13.426091"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Submit\n",
    "sub = pd.read_csv(\"data/sample_submission.csv\", index_col=0)\n",
    "sub[\"Response\"] = preds\n",
    "sub.to_csv(\"pipesubmission.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T17:40:35.619128",
     "start_time": "2016-11-01T17:40:35.612071"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183747"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.ones(y.shape[0])\n",
    "pd.Series(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T17:52:19.891813",
     "start_time": "2016-11-01T17:49:35.862641"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, ROC AUC: 0.528\n",
      "fold 1, ROC AUC: 0.546\n",
      "fold 2, ROC AUC: 0.525\n",
      "0.50391751925\n",
      "0.00504348608532\n",
      "fold 0, ROC AUC: 0.743\n",
      "fold 1, ROC AUC: 0.753\n",
      "fold 2, ROC AUC: 0.746\n",
      "0.501836863777\n",
      "0.0014234198002\n",
      "fold 0, ROC AUC: 0.753\n",
      "fold 1, ROC AUC: 0.771\n",
      "fold 2, ROC AUC: 0.753\n",
      "0.502746881773\n",
      "0.00200438547494\n",
      "fold 0, ROC AUC: 0.542\n",
      "fold 1, ROC AUC: 0.553\n",
      "fold 2, ROC AUC: 0.555\n",
      "0.486232851046\n",
      "0.00256287533878\n"
     ]
    }
   ],
   "source": [
    "preds = pd.Series(np.ones(y.shape[0]))\n",
    "\n",
    "dfX = pd.DataFrame(X)\n",
    "\n",
    "kmeans_result = pd.read_csv('train_kmeans_on_pca2comp.csv',index_col = 0,header = None)\n",
    "dfX['kmeans'] = kmeans_result.iloc[:,0]\n",
    "\n",
    "kmeans_test = pd.read_csv('test_kmeans_on_pca2comp.csv',index_col = 0,header = None)\n",
    "df_test['kmeans'] = kmeans_test.iloc[:,0]\n",
    "\n",
    "returned_predictions = pd.Series(np.ones(df_test.shape[0]))\n",
    "\n",
    "for clust,score in enumerate([0.004499,0.008154,0.003605,0.005193]):\n",
    "    onecluster = dfX[dfX.kmeans == clust]\n",
    "    preds = pd.Series(np.ones(onecluster.shape[0]))\n",
    "    test_cluster = df_test[df_test.kmeans == clust]\n",
    "    clf = XGBClassifier(max_depth=5, base_score=score, seed=37)\n",
    "    cv = StratifiedKFold(y.loc[onecluster.index], n_folds=3, random_state=37)\n",
    "    \n",
    "    for i, (infold, outfold) in enumerate(cv):\n",
    "        preds[outfold] = clf.fit(onecluster.loc[infold], y[infold]).predict_proba(onecluster.loc[outfold])[:,1]\n",
    "        print(\"fold {}, ROC AUC: {:.3f}\".format(i, roc_auc_score(y[outfold], preds[outfold])))\n",
    "    print(roc_auc_score(y.loc[onecluster.index], preds))\n",
    "\n",
    "    \n",
    "    # Pick the best threshold out-of-fold\n",
    "    thresholds = np.linspace(0.01, 0.99, 50)\n",
    "    mcc = np.array([matthews_corrcoef(y.loc[onecluster.index], preds>thr) for thr in thresholds])\n",
    "    #plt.plot(thresholds, mcc)\n",
    "    best_threshold = thresholds[mcc.argmax()]\n",
    "    print(mcc.max())\n",
    "    returned_predictions.loc[test_cluster.index] = (clf.predict_proba(test_cluster)[:,1] > best_threshold).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T17:52:19.901840",
     "start_time": "2016-11-01T17:52:19.895824"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033210615772951674\n"
     ]
    }
   ],
   "source": [
    "print(returned_predictions.sum()/len(returned_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T17:56:09.484678",
     "start_time": "2016-11-01T17:56:09.475613"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "5          0\n",
       "6          0\n",
       "7          0\n",
       "8          0\n",
       "9          0\n",
       "10         0\n",
       "11         0\n",
       "12         0\n",
       "13         0\n",
       "14         0\n",
       "15         0\n",
       "16         0\n",
       "17         0\n",
       "18         0\n",
       "19         0\n",
       "20         0\n",
       "21         0\n",
       "22         0\n",
       "23         0\n",
       "24         0\n",
       "25         0\n",
       "26         0\n",
       "27         0\n",
       "28         0\n",
       "29         0\n",
       "          ..\n",
       "1183718    1\n",
       "1183719    0\n",
       "1183720    0\n",
       "1183721    0\n",
       "1183722    0\n",
       "1183723    0\n",
       "1183724    0\n",
       "1183725    0\n",
       "1183726    0\n",
       "1183727    1\n",
       "1183728    0\n",
       "1183729    0\n",
       "1183730    0\n",
       "1183731    1\n",
       "1183732    0\n",
       "1183733    0\n",
       "1183734    0\n",
       "1183735    0\n",
       "1183736    0\n",
       "1183737    0\n",
       "1183738    1\n",
       "1183739    0\n",
       "1183740    0\n",
       "1183741    0\n",
       "1183742    0\n",
       "1183743    0\n",
       "1183744    0\n",
       "1183745    0\n",
       "1183746    0\n",
       "1183747    0\n",
       "dtype: int32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_predictions.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-01T17:56:28.976712",
     "start_time": "2016-11-01T17:56:22.756133"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Submit\n",
    "sub = pd.read_csv(\"data/sample_submission.csv\", index_col=0)\n",
    "sub[\"Response\"] = returned_predictions.astype('int').values\n",
    "sub.to_csv(\"pipesubmission.csv.gz\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
